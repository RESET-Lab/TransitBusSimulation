{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_DATA_PATH = '../Data/Speed Data/Merged' \n",
    "GRADIENT_DATA_PATH = '../Data/Gradient Data/Adjusted/'\n",
    "OUTPUT_PATH = '../Data/Cycle Data/Original'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(geom,possible):\n",
    "    '''\n",
    "    \n",
    "    Input:\n",
    "    geom - LineString geometry of bus route segment\n",
    "    possible - LineString geometry of associated speed mesh segments found through spatial joining\n",
    "    \n",
    "    Output:\n",
    "    i - index of possible which has the smallest angle with geom\n",
    "    \n",
    "    '''\n",
    "    dy = geom.coords[1][1] - geom.coords[0][1]\n",
    "    dx = geom.coords[1][0] - geom.coords[0][0]\n",
    "    \n",
    "    theta = np.arctan2(dy,dx)\n",
    "    \n",
    "    ans = 0\n",
    "    close = 100000\n",
    "    \n",
    "    for i,e in enumerate(possible):\n",
    "        dy = e.coords[1][1] - e.coords[0][1]\n",
    "        dx = e.coords[1][0] - e.coords[0][0]\n",
    "    \n",
    "        t_theta = np.arctan2(dy,dx)\n",
    "        \n",
    "        if(abs(theta-t_theta) < close):\n",
    "            close = abs(theta-t_theta)\n",
    "            ans = i\n",
    "    \n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_speed(df, route):\n",
    "    \n",
    "    '''\n",
    "    Uses spatial joining to add speed data to route GeoDataFrame\n",
    "    \n",
    "    Input:\n",
    "    df - GeoDataFrame of bucketed speed mesh\n",
    "    route - GeoDataFrame of bus route \n",
    "    \n",
    "    Output\n",
    "    None\n",
    "    '''\n",
    "    result = gpd.sjoin(route,df)\n",
    "    \n",
    "    speeds = np.zeros(len(route['geometry']))\n",
    "            \n",
    "    for idx in set(result.index):\n",
    "        cur = list(result['index_right'][result.index == idx])\n",
    "\n",
    "        ind = closest(route['geometry'][idx],list(df['non_buffered'][cur]))\n",
    "        poss = list(df['speed'][cur])\n",
    "\n",
    "        speeds[idx] = poss[ind]\n",
    "\n",
    "    route['speed'] = speeds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cycle(route, out_path):\n",
    "    '''\n",
    "    TODO: DOCUMENTATION\n",
    "    '''\n",
    "    speeds = []\n",
    "    grades = []\n",
    "\n",
    "    time_left = 1\n",
    "    cur_speed = 0\n",
    "    cur_grade = 0\n",
    "    empty = 0\n",
    "\n",
    "    avg_speed = np.mean(route['speed'][route['speed'] != 0])\n",
    "    \n",
    "    for i in range(len(route['geometry'])):\n",
    "        geom = route['geometry'][i]\n",
    "        speed = route['speed'][i] \n",
    "        if speed == 0:\n",
    "            empty += 1\n",
    "            speed = avg_speed\n",
    "        grade = route['grade'][i]\n",
    "        len_left = geom.length\n",
    "        while(len_left > 0):\n",
    "            if(len_left > speed*time_left):\n",
    "                len_left -= speed*time_left\n",
    "                cur_speed += time_left*speed\n",
    "                cur_grade += time_left*grade\n",
    "                grades.append(cur_grade)\n",
    "                speeds.append(cur_speed)\n",
    "                cur_speed = 0\n",
    "                cur_grade = 0\n",
    "                time_left = 1\n",
    "            else:\n",
    "                time_spent = len_left/speed \n",
    "                len_left = 0\n",
    "                time_left -= time_spent\n",
    "                cur_speed += time_spent*speed\n",
    "                cur_grade += time_spent*grade\n",
    "                \n",
    "    f = open(out_path, \"w\")\n",
    "    f.write(\"cycSecs,cycMps,cycGrade,cycRoadType\\n\")\n",
    "    for i in range(len(grades)):\n",
    "        f.write(str(i) + \",\" + str(speeds[i]) + \",\" + str(grades[i]) +\",0\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Speed Data:   8%|â–Š        | 1/12 [00:20<03:46, 20.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-348836b670b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmonth_bucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour_bucket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMERGED_DATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%d_%d.shp\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmonth_bucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour_bucket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epsg:32614'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\machinelearning\\lib\\site-packages\\geopandas\\io\\file.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"schema\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"properties\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"geometry\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mgdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_filt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\machinelearning\\lib\\site-packages\\geopandas\\geodataframe.py\u001b[0m in \u001b[0;36mfrom_features\u001b[1;34m(cls, features, crs, columns)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures_lst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__geo_interface__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__geo_interface__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "speed_dfs = []\n",
    "\n",
    "\n",
    "for month_bucket in range(4):\n",
    "    speed_dfs.append([])\n",
    "    \n",
    "for k in tqdm(range(12),'Loading Speed Data'):\n",
    "    month_bucket, hour_bucket = k//3, k%3\n",
    "    path = os.path.join(MERGED_DATA_PATH, \"%d_%d.shp\" % (month_bucket, hour_bucket))\n",
    "    df = gpd.read_file(path)\n",
    "    df = df.to_crs('epsg:32614')\n",
    "    \n",
    "    df['non_buffered'] = df['geometry']\n",
    "    df['geometry'] = df['geometry'].buffer(20)\n",
    "\n",
    "    speed_dfs[month_bucket].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: '../Data/Cycle Data/Original\\\\0_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8985a432b9fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mbucket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%d_%d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmonth_bucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour_bucket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mbucket_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: '../Data/Cycle Data/Original\\\\0_0'"
     ]
    }
   ],
   "source": [
    "for month_bucket in range(4):\n",
    "    for hour_bucket in range(3):\n",
    "        bucket = \"%d_%d\" % (month_bucket, hour_bucket)\n",
    "        bucket_path = os.path.join(OUTPUT_PATH, bucket)\n",
    "        os.mkdir(bucket_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cycle Generation:   0%|               | 0/109 [00:10<?, ?route/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ff8bb08ff6d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhour_bucket\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeed_dfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmonth_bucket\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhour_bucket\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mbucket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%d_%d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmonth_bucket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhour_bucket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "shps = []\n",
    "for file in os.listdir(GRADIENT_DATA_PATH):\n",
    "    if \".shp\" in file:\n",
    "        shps.append(file)\n",
    "\n",
    "for file in tqdm(shps, 'Cycle Generation', unit = 'route'):\n",
    "    \n",
    "    route = gpd.read_file(os.path.join(GRADIENT_DATA_PATH,file))\n",
    "    route.crs = 'epsg:32614'\n",
    "    \n",
    "    for month_bucket in range(4):\n",
    "        for hour_bucket in range(3):\n",
    "            \n",
    "            df = speed_dfs[month_bucket][hour_bucket]\n",
    "            \n",
    "            bucket = \"%d_%d\" % (month_bucket, hour_bucket)\n",
    "            \n",
    "            out_path = os.path.join(OUTPUT_PATH, bucket, file.replace(\"shp\",\"csv\"))\n",
    "            \n",
    "            add_speed(df, route)\n",
    "            \n",
    "            to_cycle(route, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
